{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_LSTM.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaNX0BUTnihb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c9eb8ecc-ad62-408b-9432-69754e4b4ef4"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP954twVnvwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_-DeEwln5ut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bb0ec17e-7c5d-486d-d5c4-5f7723fae655"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwJaS0Xsn90j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS0kF_ploBUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0423b3a8-8165-44bf-d23c-c1c1f57ae817"
      },
      "source": [
        "!kaggle competitions download -c quora-insincere-questions-classification"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv.zip to {/content}/competitions/quora-insincere-questions-classification\n",
            " 96% 52.0M/54.4M [00:02<00:00, 12.9MB/s]\n",
            "100% 54.4M/54.4M [00:02<00:00, 19.2MB/s]\n",
            "Downloading embeddings.zip to {/content}/competitions/quora-insincere-questions-classification\n",
            "100% 5.95G/5.96G [01:53<00:00, 43.4MB/s]\n",
            "100% 5.96G/5.96G [01:53<00:00, 56.4MB/s]\n",
            "Downloading sample_submission.csv.zip to {/content}/competitions/quora-insincere-questions-classification\n",
            "100% 4.08M/4.08M [00:00<00:00, 20.4MB/s]\n",
            "\n",
            "Downloading test.csv.zip to {/content}/competitions/quora-insincere-questions-classification\n",
            " 57% 9.00M/15.7M [00:00<00:00, 12.8MB/s]\n",
            "100% 15.7M/15.7M [00:00<00:00, 18.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLcyXNj0ot4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "96b7039e-0357-4a01-be01-aaf6e20013a9"
      },
      "source": [
        "!unzip /content/{/content}/competitions/quora-insincere-questions-classification/embeddings.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/{/content}/competitions/quora-insincere-questions-classification/embeddings.zip\n",
            "   creating: GoogleNews-vectors-negative300/\n",
            "   creating: glove.840B.300d/\n",
            "   creating: paragram_300_sl999/\n",
            "   creating: wiki-news-300d-1M/\n",
            "  inflating: glove.840B.300d/glove.840B.300d.txt  \n",
            "  inflating: GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \n",
            "  inflating: wiki-news-300d-1M/wiki-news-300d-1M.vec  \n",
            "  inflating: paragram_300_sl999/README.txt  \n",
            "  inflating: paragram_300_sl999/paragram_300_sl999.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1DMcUa6piL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "779d04cf-3bfc-4fe1-eddf-ac178579ae82"
      },
      "source": [
        "#Importing the libraries\n",
        "import os\n",
        "import time\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, Flatten, GlobalAveragePooling1D, Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySrVf_7XpqTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e945833c-eae6-4700-e10e-a6414ce1bf73"
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "print(\"Train shape : \",train_df.shape)\n",
        "print(\"Test shape : \",test_df.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (1306122, 3)\n",
            "Test shape :  (375806, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijk5ZuJcp1J9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## split to train and val\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.08, random_state=2018)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFvdY5iOp3ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## some config values \n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 95000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 70 # max number of words in a question to use"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIn3_78vp9Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## fill up the missing values\n",
        "train_X = train_df[\"question_text\"].fillna(\"_##_\").values\n",
        "val_X = val_df[\"question_text\"].fillna(\"_##_\").values\n",
        "test_X = test_df[\"question_text\"].fillna(\"_##_\").values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yzeSly3qDFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "val_X = tokenizer.texts_to_sequences(val_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9T_RQ7sqYiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Pad the sentences \n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqKFA4Zxqea1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Get the target values\n",
        "train_y = train_df['target'].values\n",
        "val_y = val_df['target'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKDmVO1aqh9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shuffling the data\n",
        "np.random.seed(2018)\n",
        "trn_idx = np.random.permutation(len(train_X))\n",
        "val_idx = np.random.permutation(len(val_X))\n",
        "\n",
        "train_X = train_X[trn_idx]\n",
        "val_X = val_X[val_idx]\n",
        "train_y = train_y[trn_idx]\n",
        "val_y = val_y[val_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXj3ENZaqypK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "037fd746-201d-4f9e-f87e-fb3ec4916abb"
      },
      "source": [
        "EMBEDDING_FILE = 'glove.840B.300d/glove.840B.300d.txt'\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ElzSRRZse_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random, os, sys\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *\n",
        "from keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from keras.engine.topology import Layer\n",
        "\n",
        "try:\n",
        "    from dataloader import TokenList, pad_to_longest\n",
        "    # for transformer\n",
        "except: pass\n",
        "\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "class ScaledDotProductAttention():\n",
        "    def __init__(self, d_model, attn_dropout=0.1):\n",
        "        self.temper = np.sqrt(d_model)\n",
        "        self.dropout = Dropout(attn_dropout)\n",
        "    def __call__(self, q, k, v, mask):\n",
        "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k])\n",
        "        if mask is not None:\n",
        "            mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
        "            attn = Add()([attn, mmask])\n",
        "        attn = Activation('softmax')(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
        "        return output, attn\n",
        "\n",
        "class MultiHeadAttention():\n",
        "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
        "    def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True):\n",
        "        self.mode = mode\n",
        "        self.n_head = n_head\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.dropout = dropout\n",
        "        if mode == 0:\n",
        "            self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
        "            self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
        "            self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
        "        elif mode == 1:\n",
        "            self.qs_layers = []\n",
        "            self.ks_layers = []\n",
        "            self.vs_layers = []\n",
        "            for _ in range(n_head):\n",
        "                self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
        "                self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
        "                self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
        "        self.attention = ScaledDotProductAttention(d_model)\n",
        "        self.layer_norm = LayerNormalization() if use_norm else None\n",
        "        self.w_o = TimeDistributed(Dense(d_model))\n",
        "\n",
        "    def __call__(self, q, k, v, mask=None):\n",
        "        d_k, d_v = self.d_k, self.d_v\n",
        "        n_head = self.n_head\n",
        "\n",
        "        if self.mode == 0:\n",
        "            qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
        "            ks = self.ks_layer(k)\n",
        "            vs = self.vs_layer(v)\n",
        "\n",
        "            def reshape1(x):\n",
        "                s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
        "                x = tf.reshape(x, [s[0], s[1], n_head, d_k])\n",
        "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
        "                x = tf.reshape(x, [-1, s[1], d_k])  # [n_head * batch_size, len_q, d_k]\n",
        "                return x\n",
        "            qs = Lambda(reshape1)(qs)\n",
        "            ks = Lambda(reshape1)(ks)\n",
        "            vs = Lambda(reshape1)(vs)\n",
        "\n",
        "            if mask is not None:\n",
        "                mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
        "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
        "                \n",
        "            def reshape2(x):\n",
        "                s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
        "                x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
        "                x = tf.transpose(x, [1, 2, 0, 3])\n",
        "                x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
        "                return x\n",
        "            head = Lambda(reshape2)(head)\n",
        "        elif self.mode == 1:\n",
        "            heads = []; attns = []\n",
        "            for i in range(n_head):\n",
        "                qs = self.qs_layers[i](q)   \n",
        "                ks = self.ks_layers[i](k) \n",
        "                vs = self.vs_layers[i](v) \n",
        "                head, attn = self.attention(qs, ks, vs, mask)\n",
        "                heads.append(head); attns.append(attn)\n",
        "            head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
        "            attn = Concatenate()(attns) if n_head > 1 else attns[0]\n",
        "\n",
        "        outputs = self.w_o(head)\n",
        "        outputs = Dropout(self.dropout)(outputs)\n",
        "        if not self.layer_norm: return outputs, attn\n",
        "        # outputs = Add()([outputs, q]) # sl: fix\n",
        "        return self.layer_norm(outputs), attn\n",
        "\n",
        "class PositionwiseFeedForward():\n",
        "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
        "        self.w_1 = Conv1D(d_inner_hid, 1, activation='relu')\n",
        "        self.w_2 = Conv1D(d_hid, 1)\n",
        "        self.layer_norm = LayerNormalization()\n",
        "        self.dropout = Dropout(dropout)\n",
        "    def __call__(self, x):\n",
        "        output = self.w_1(x) \n",
        "        output = self.w_2(output)\n",
        "        output = self.dropout(output)\n",
        "        output = Add()([output, x])\n",
        "        return self.layer_norm(output)\n",
        "\n",
        "class EncoderLayer():\n",
        "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
        "        self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
        "    def __call__(self, enc_input, mask=None):\n",
        "        output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
        "        output = self.pos_ffn_layer(output)\n",
        "        return output, slf_attn\n",
        "\n",
        "\n",
        "def GetPosEncodingMatrix(max_len, d_emb):\n",
        "    pos_enc = np.array([\n",
        "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
        "        if pos != 0 else np.zeros(d_emb) \n",
        "            for pos in range(max_len)\n",
        "            ])\n",
        "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
        "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
        "    return pos_enc\n",
        "\n",
        "def GetPadMask(q, k):\n",
        "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
        "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
        "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
        "    return mask\n",
        "\n",
        "def GetSubMask(s):\n",
        "    len_s = tf.shape(s)[1]\n",
        "    bs = tf.shape(s)[:1]\n",
        "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
        "    return mask\n",
        "\n",
        "class Transformer():\n",
        "    def __init__(self, len_limit, embedding_matrix, d_model=embed_size, \\\n",
        "              d_inner_hid=512, n_head=10, d_k=64, d_v=64, layers=2, dropout=0.1, \\\n",
        "              share_word_emb=False, **kwargs):\n",
        "        self.name = 'Transformer'\n",
        "        self.len_limit = len_limit\n",
        "        self.src_loc_info = False # True # sl: fix later\n",
        "        self.d_model = d_model\n",
        "        self.decode_model = None\n",
        "        d_emb = d_model\n",
        "\n",
        "        pos_emb = Embedding(len_limit, d_emb, trainable=False, \\\n",
        "                            weights=[GetPosEncodingMatrix(len_limit, d_emb)])\n",
        "\n",
        "        i_word_emb = Embedding(max_features, d_emb, weights=[embedding_matrix]) # Add Kaggle provided embedding here\n",
        "\n",
        "         \n",
        "        self.encoder = EncoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout)\n",
        "\n",
        "        \n",
        "    def get_pos_seq(self, x):\n",
        "        mask = K.cast(K.not_equal(x, 0), 'int32')\n",
        "        pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
        "        return pos * mask\n",
        "\n",
        "    def compile(self, active_layers=999):\n",
        "        src_seq_input = Input(shape=(None, ))\n",
        "        x = Embedding(max_features, embed_size, weights=[embedding_matrix])(src_seq_input)\n",
        "        \n",
        "        # LSTM before attention layers\n",
        "        x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
        "        x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x) \n",
        "        \n",
        "        x, slf_attn = MultiHeadAttention(n_head=3, d_model=300, d_k=64, d_v=64, dropout=0.1)(x, x, x)\n",
        "        \n",
        "        avg_pool = GlobalAveragePooling1D()(x)\n",
        "        max_pool = GlobalMaxPooling1D()(x)\n",
        "        conc = concatenate([avg_pool, max_pool])\n",
        "        conc = Dense(64, activation=\"relu\")(conc)\n",
        "        x = Dense(1, activation=\"sigmoid\")(conc)   \n",
        "        \n",
        "        \n",
        "        self.model = Model(inputs=src_seq_input, outputs=x)\n",
        "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0APMZHa2swhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cbeb7ca-e761-42ee-9231-caeefd506414"
      },
      "source": [
        "s2s = Transformer(64, embedding_matrix, layers=1)\n",
        "s2s.compile()\n",
        "model = s2s.model\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, None, 300)    28500000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, None, 256)    440320      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, None, 128)    164864      bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, None, 192)    24576       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, None, 192)    24576       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, None, 64)     0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, None, 64)     0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, None, None)   0           lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None)   0           lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, None, 192)    24576       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, None, None)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, None, 64)     0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, None, 64)     0           dropout_3[0][0]                  \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, None, 192)    0           lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, None, 300)    57900       lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, None, 300)    0           time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNor (None, None, 300)    600         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 300)          0           layer_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 300)          0           layer_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 64)           38464       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            65          dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 29,275,941\n",
            "Trainable params: 29,275,941\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03-pBzltyW64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "cc0de93c-e2a1-4cfa-98e2-1902853dd651"
      },
      "source": [
        "## Train the model \n",
        "model.fit(train_X, train_y, batch_size=512, epochs=3, validation_data=(val_X, val_y))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 1201632 samples, validate on 104490 samples\n",
            "Epoch 1/3\n",
            "1201632/1201632 [==============================] - 639s 532us/step - loss: 0.1137 - acc: 0.9555 - val_loss: 0.1021 - val_acc: 0.9583\n",
            "Epoch 2/3\n",
            "1201632/1201632 [==============================] - 636s 529us/step - loss: 0.0921 - acc: 0.9630 - val_loss: 0.1012 - val_acc: 0.9597\n",
            "Epoch 3/3\n",
            "1201632/1201632 [==============================] - 636s 529us/step - loss: 0.0771 - acc: 0.9692 - val_loss: 0.1072 - val_acc: 0.9583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9e40631a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYFm59GE6gOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "bd6b1548-ab24-4bf4-c390-bffacc03dd28"
      },
      "source": [
        "pred_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "\n",
        "thresholds = []\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    res = metrics.f1_score(val_y, (pred_val_y > thresh).astype(int))\n",
        "    thresholds.append([thresh, res])\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
        "    \n",
        "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
        "best_thresh = thresholds[0][0]\n",
        "print(\"Best threshold: \", best_thresh)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104490/104490 [==============================] - 13s 128us/step\n",
            "F1 score at threshold 0.1 is 0.5957044583311453\n",
            "F1 score at threshold 0.11 is 0.6052306535631814\n",
            "F1 score at threshold 0.12 is 0.613400647533337\n",
            "F1 score at threshold 0.13 is 0.618049734562727\n",
            "F1 score at threshold 0.14 is 0.6253919388860384\n",
            "F1 score at threshold 0.15 is 0.6303339517625232\n",
            "F1 score at threshold 0.16 is 0.6366107303238004\n",
            "F1 score at threshold 0.17 is 0.6409792571152918\n",
            "F1 score at threshold 0.18 is 0.645359557467732\n",
            "F1 score at threshold 0.19 is 0.6495715804615674\n",
            "F1 score at threshold 0.2 is 0.6530508366736654\n",
            "F1 score at threshold 0.21 is 0.6559028674761045\n",
            "F1 score at threshold 0.22 is 0.6579240705527507\n",
            "F1 score at threshold 0.23 is 0.6603259062188228\n",
            "F1 score at threshold 0.24 is 0.6632494773049167\n",
            "F1 score at threshold 0.25 is 0.6647525293956795\n",
            "F1 score at threshold 0.26 is 0.6658828411370081\n",
            "F1 score at threshold 0.27 is 0.6664333216660833\n",
            "F1 score at threshold 0.28 is 0.6667610419026048\n",
            "F1 score at threshold 0.29 is 0.6664755625627061\n",
            "F1 score at threshold 0.3 is 0.6662324504269793\n",
            "F1 score at threshold 0.31 is 0.6655435101084091\n",
            "F1 score at threshold 0.32 is 0.664743305222666\n",
            "F1 score at threshold 0.33 is 0.6629801225526827\n",
            "F1 score at threshold 0.34 is 0.6640012070006035\n",
            "F1 score at threshold 0.35 is 0.6631170609264471\n",
            "F1 score at threshold 0.36 is 0.6610962054426984\n",
            "F1 score at threshold 0.37 is 0.6605405405405406\n",
            "F1 score at threshold 0.38 is 0.6590431738623105\n",
            "F1 score at threshold 0.39 is 0.6583967967339248\n",
            "F1 score at threshold 0.4 is 0.6563786008230452\n",
            "F1 score at threshold 0.41 is 0.653149197732897\n",
            "F1 score at threshold 0.42 is 0.6507477086348288\n",
            "F1 score at threshold 0.43 is 0.6498785425101214\n",
            "F1 score at threshold 0.44 is 0.6474139337575461\n",
            "F1 score at threshold 0.45 is 0.6459035253513026\n",
            "F1 score at threshold 0.46 is 0.6447019867549669\n",
            "F1 score at threshold 0.47 is 0.6415094339622641\n",
            "F1 score at threshold 0.48 is 0.6381795195954488\n",
            "F1 score at threshold 0.49 is 0.6312457221081451\n",
            "F1 score at threshold 0.5 is 0.6188850967007964\n",
            "Best threshold:  0.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23g6_AxS6r7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aafca29e-32be-4205-b64f-8d3cc330f862"
      },
      "source": [
        "pred_test_y = model.predict([test_X], batch_size=1024, verbose=1)\n",
        "\n",
        "pred_test_y = (pred_test_y > best_thresh).astype(int)\n",
        "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
        "out_df['prediction'] = pred_test_y\n",
        "out_df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375806/375806 [==============================] - 47s 125us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}